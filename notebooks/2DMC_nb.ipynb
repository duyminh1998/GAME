{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying out OpenAI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('MountainCar-v0', render_mode = 'human')\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a Sarsa(lambda) agent on 2D Mountain Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GAME.envs.mountain_car\n",
    "import gym\n",
    "from GAME.agents.sarsa_lambda import SarsaLambdaCMAC2DMountainCar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Number of steps: 2280, Total steps: 2280\n",
      "Episode: 1, Number of steps: 2235, Total steps: 4515\n",
      "Episode: 2, Number of steps: 1096, Total steps: 5611\n",
      "Episode: 3, Number of steps: 669, Total steps: 6280\n",
      "Episode: 4, Number of steps: 494, Total steps: 6774\n",
      "Episode: 5, Number of steps: 351, Total steps: 7125\n",
      "Episode: 6, Number of steps: 263, Total steps: 7388\n",
      "Episode: 7, Number of steps: 185, Total steps: 7573\n",
      "Episode: 8, Number of steps: 280, Total steps: 7853\n",
      "Episode: 9, Number of steps: 317, Total steps: 8170\n",
      "Episode: 10, Number of steps: 264, Total steps: 8434\n",
      "Episode: 11, Number of steps: 266, Total steps: 8700\n",
      "Episode: 12, Number of steps: 244, Total steps: 8944\n",
      "Episode: 13, Number of steps: 195, Total steps: 9139\n",
      "Episode: 14, Number of steps: 192, Total steps: 9331\n",
      "Episode: 15, Number of steps: 149, Total steps: 9480\n",
      "Episode: 16, Number of steps: 155, Total steps: 9635\n",
      "Episode: 17, Number of steps: 135, Total steps: 9770\n",
      "Episode: 18, Number of steps: 164, Total steps: 9934\n",
      "Episode: 19, Number of steps: 145, Total steps: 10079\n",
      "Episode: 20, Number of steps: 149, Total steps: 10228\n",
      "Episode: 21, Number of steps: 111, Total steps: 10339\n",
      "Episode: 22, Number of steps: 145, Total steps: 10484\n",
      "Episode: 23, Number of steps: 158, Total steps: 10642\n",
      "Episode: 24, Number of steps: 157, Total steps: 10799\n",
      "Episode: 25, Number of steps: 114, Total steps: 10913\n",
      "Episode: 26, Number of steps: 111, Total steps: 11024\n",
      "Episode: 27, Number of steps: 110, Total steps: 11134\n",
      "Episode: 28, Number of steps: 111, Total steps: 11245\n",
      "Episode: 29, Number of steps: 109, Total steps: 11354\n",
      "Episode: 30, Number of steps: 109, Total steps: 11463\n",
      "Episode: 31, Number of steps: 90, Total steps: 11553\n",
      "Episode: 32, Number of steps: 110, Total steps: 11663\n",
      "Episode: 33, Number of steps: 108, Total steps: 11771\n",
      "Episode: 34, Number of steps: 108, Total steps: 11879\n",
      "Episode: 35, Number of steps: 111, Total steps: 11990\n",
      "Episode: 36, Number of steps: 111, Total steps: 12101\n",
      "Episode: 37, Number of steps: 108, Total steps: 12209\n",
      "Episode: 38, Number of steps: 110, Total steps: 12319\n",
      "Episode: 39, Number of steps: 105, Total steps: 12424\n",
      "Episode: 40, Number of steps: 108, Total steps: 12532\n",
      "Episode: 41, Number of steps: 101, Total steps: 12633\n",
      "Episode: 42, Number of steps: 105, Total steps: 12738\n",
      "Episode: 43, Number of steps: 109, Total steps: 12847\n",
      "Episode: 44, Number of steps: 101, Total steps: 12948\n",
      "Episode: 45, Number of steps: 101, Total steps: 13049\n",
      "Episode: 46, Number of steps: 108, Total steps: 13157\n",
      "Episode: 47, Number of steps: 109, Total steps: 13266\n",
      "Episode: 48, Number of steps: 105, Total steps: 13371\n",
      "Episode: 49, Number of steps: 111, Total steps: 13482\n",
      "Average steps per episode: 269.64\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar2D-v0', render_mode = 'human')\n",
    "env._max_episode_steps = 4000\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# agent\n",
    "alpha = 1.2\n",
    "lamb = 0.95\n",
    "gamma = 1\n",
    "method = 'replacing'\n",
    "epsilon = 0\n",
    "num_of_tilings = 8\n",
    "max_size = 2048\n",
    "agent = SarsaLambdaCMAC2DMountainCar(alpha, lamb, gamma, method, epsilon, num_of_tilings, max_size)\n",
    "\n",
    "# experiment parameters\n",
    "max_episodes = 50\n",
    "total_steps = 0 # eval metric\n",
    "update_agent = True\n",
    "debug = True\n",
    "\n",
    "for ep in range(max_episodes):\n",
    "    steps = 0\n",
    "    while True:\n",
    "        # current state\n",
    "        current_state = observation # [x, x_dot]\n",
    "        action = agent.choose_action_eps_greedy(current_state)\n",
    "        # next state\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        # next action\n",
    "        next_action = agent.choose_action_eps_greedy(observation)\n",
    "        # env.render()\n",
    "\n",
    "        # update agent\n",
    "        if update_agent:\n",
    "            target = reward + agent.get_value(observation, next_action)\n",
    "            active_tiles = agent.get_active_tiles(current_state, action)\n",
    "            agent.update(active_tiles, target)\n",
    "\n",
    "        # prep the next iteration\n",
    "        steps += 1\n",
    "\n",
    "        # reset the training\n",
    "        if terminated or truncated:\n",
    "            observation, info = env.reset()\n",
    "            total_steps += steps\n",
    "            if debug:\n",
    "                print(\"Episode: {}, Number of steps: {}, Total steps: {}\".format(ep, steps, total_steps))\n",
    "            break\n",
    "\n",
    "# training complete\n",
    "env.close()\n",
    "print(\"Average steps per episode: {}\".format(total_steps / max_episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving training information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the agent\n",
    "path = \"C:\\\\Users\\\\minhh\\\\Documents\\\\JHU\\\\Fall 2022\\\\Evolutionary and Swarm Intelligence\\\\src\\\\GAME\\\\pickle\\\\10242022 Initial Experiments with 2D MC and Sarsa\\\\\"\n",
    "agent_filename = 'agent_alpha_{:.2f}_lamb_{:.2f}_gam_{:.2f}_eps_{:.2f}_method_{}_ntiles_{}_max_size_{}.pickle'.format(alpha, lamb, gamma, epsilon, method, num_of_tilings, max_size)\n",
    "agent_weights_filename = 'weights_alpha_{:.2f}_lamb_{:.2f}_gam_{:.2f}_eps_{:.2f}_method_{}_ntiles_{}_max_size_{}.pickle'.format(alpha, lamb, gamma, epsilon, method, num_of_tilings, max_size)\n",
    "agent_hash_filename = 'hash_alpha_{:.2f}_lamb_{:.2f}_gam_{:.2f}_eps_{:.2f}_method_{}_ntiles_{}_max_size_{}.pickle'.format(alpha, lamb, gamma, epsilon, method, num_of_tilings, max_size)\n",
    "agent_z_filename = 'z_alpha_{:.2f}_lamb_{:.2f}_gam_{:.2f}_eps_{:.2f}_method_{}_ntiles_{}_max_size_{}.pickle'.format(alpha, lamb, gamma, epsilon, method, num_of_tilings, max_size)\n",
    "\n",
    "with open(path + agent_filename, 'wb') as f:\n",
    "    pickle.dump(agent, f)\n",
    "with open(path + agent_weights_filename, 'wb') as f:\n",
    "    pickle.dump(agent.weights, f)\n",
    "with open(path + agent_hash_filename, 'wb') as f:\n",
    "    pickle.dump(agent.hash_table, f)\n",
    "with open(path + agent_z_filename, 'wb') as f:\n",
    "    pickle.dump(agent.z, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + agent_filename, 'rb') as f:\n",
    "    agent2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Number of steps: 105, Total steps: 105\n",
      "Average steps per episode: 105.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar2D-v0', render_mode = 'human')\n",
    "env._max_episode_steps = 4000\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# experiment parameters\n",
    "max_episodes = 1\n",
    "total_steps = 0 # eval metric\n",
    "update_agent = False\n",
    "debug = True\n",
    "\n",
    "for ep in range(max_episodes):\n",
    "    steps = 0\n",
    "    while True:\n",
    "        # current state\n",
    "        current_state = observation # [x, x_dot]\n",
    "        action = agent2.choose_action_eps_greedy(current_state)\n",
    "        # next state\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        # next action\n",
    "        next_action = agent2.choose_action_eps_greedy(observation)\n",
    "        # env.render()\n",
    "\n",
    "        # update agent\n",
    "        if update_agent:\n",
    "            target = reward + agent2.get_value(observation, next_action)\n",
    "            active_tiles = agent2.get_active_tiles(current_state, action)\n",
    "            agent2.update(active_tiles, target)\n",
    "\n",
    "        # prep the next iteration\n",
    "        steps += 1\n",
    "\n",
    "        # reset the training\n",
    "        if terminated or truncated:\n",
    "            observation, info = env.reset()\n",
    "            total_steps += steps\n",
    "            if debug:\n",
    "                print(\"Episode: {}, Number of steps: {}, Total steps: {}\".format(ep, steps, total_steps))\n",
    "            break\n",
    "\n",
    "# training complete\n",
    "env.close()\n",
    "print(\"Average steps per episode: {}\".format(total_steps / max_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + agent_weights_filename, 'rb') as f:\n",
    "    agent_weights = pickle.load(f)\n",
    "with open(path + agent_hash_filename, 'rb') as f:\n",
    "    agent_hash_tab = pickle.load(f)\n",
    "with open(path + agent_z_filename, 'rb') as f:\n",
    "    agent_z = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Number of steps: 105, Total steps: 105\n",
      "Average steps per episode: 105.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar2D-v0', render_mode = 'human')\n",
    "env._max_episode_steps = 4000\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# agent\n",
    "alpha = 1.2\n",
    "lamb = 0.95\n",
    "gamma = 1\n",
    "method = 'replacing'\n",
    "epsilon = 0\n",
    "num_of_tilings = 8\n",
    "max_size = 2048\n",
    "agent3 = SarsaLambdaCMAC2DMountainCar(alpha, lamb, gamma, method, epsilon, num_of_tilings, max_size)\n",
    "agent3.weights = agent_weights\n",
    "agent3.hash_table = agent_hash_tab\n",
    "agent3.z = agent_z\n",
    "\n",
    "# experiment parameters\n",
    "max_episodes = 1\n",
    "total_steps = 0 # eval metric\n",
    "update_agent = False\n",
    "debug = True\n",
    "\n",
    "for ep in range(max_episodes):\n",
    "    steps = 0\n",
    "    while True:\n",
    "        # current state\n",
    "        current_state = observation # [x, x_dot]\n",
    "        action = agent3.choose_action_eps_greedy(current_state)\n",
    "        # next state\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        # next action\n",
    "        next_action = agent3.choose_action_eps_greedy(observation)\n",
    "        # env.render()\n",
    "\n",
    "        # update agent\n",
    "        if update_agent:\n",
    "            target = reward + agent3.get_value(observation, next_action)\n",
    "            active_tiles = agent3.get_active_tiles(current_state, action)\n",
    "            agent3.update(active_tiles, target)\n",
    "\n",
    "        # prep the next iteration\n",
    "        steps += 1\n",
    "\n",
    "        # reset the training\n",
    "        if terminated or truncated:\n",
    "            observation, info = env.reset()\n",
    "            total_steps += steps\n",
    "            if debug:\n",
    "                print(\"Episode: {}, Number of steps: {}, Total steps: {}\".format(ep, steps, total_steps))\n",
    "            break\n",
    "\n",
    "# training complete\n",
    "env.close()\n",
    "print(\"Average steps per episode: {}\".format(total_steps / max_episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting samples for 2D MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GAME.envs.mountain_car\n",
    "import gym\n",
    "from GAME.agents.sarsa_lambda import SarsaLambdaCMAC2DMountainCar\n",
    "from GAME.utils.helper_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar2D-v0', render_mode = 'human')\n",
    "env._max_episode_steps = 3000\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# agent\n",
    "alpha = 1.2\n",
    "lamb = 0.95\n",
    "gamma = 1\n",
    "method = 'replacing'\n",
    "epsilon = 0\n",
    "num_of_tilings = 8\n",
    "max_size = 2048\n",
    "agent = SarsaLambdaCMAC2DMountainCar(alpha, lamb, gamma, method, epsilon, num_of_tilings, max_size)\n",
    "\n",
    "# experiment parameters\n",
    "max_episodes = 50\n",
    "total_steps = 0 # eval metric\n",
    "update_agent = True\n",
    "debug = True\n",
    "\n",
    "# data collector\n",
    "save_every = 10\n",
    "agent_info = SarsaLambdaAgentInfo(alpha, lamb, gamma, method, epsilon, num_of_tilings, max_size)\n",
    "experiment_info = ExperimentInfo('MountainCar2D-v0', env._max_episode_steps, 42, max_episodes, 'SarsaLambda')\n",
    "data_column_names = ['Episode', 'Step', 'Current_x_position', 'Current_x_velocity', 'Current_action', 'Reward', 'Next_x_position', 'Next_x_velocity', 'Next_action']\n",
    "data_column_dtypes = ['int', 'int', 'float', 'float', 'int', 'int', 'float', 'float', 'int']\n",
    "data_collector = RLSamplesCollector(experiment_info, agent_info, data_column_names, data_column_dtypes)\n",
    "path = \"C:\\\\Users\\\\minhh\\\\Documents\\\\JHU\\\\Fall 2022\\\\Evolutionary and Swarm Intelligence\\\\src\\\\GAME\\\\output\\\\10242022 Initial Samples Collection for 2D MC\\\\\"\n",
    "file_name = 'test.csv'\n",
    "data_collector.write_metadata(path, 'test_metadata.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Number of steps: 1040, Total steps: 1040\n",
      "Episode: 1, Number of steps: 1305, Total steps: 2345\n",
      "Episode: 2, Number of steps: 1048, Total steps: 3393\n",
      "Episode: 3, Number of steps: 784, Total steps: 4177\n",
      "Episode: 4, Number of steps: 958, Total steps: 5135\n",
      "Episode: 5, Number of steps: 286, Total steps: 5421\n",
      "Episode: 6, Number of steps: 1447, Total steps: 6868\n",
      "Episode: 7, Number of steps: 860, Total steps: 7728\n",
      "Episode: 8, Number of steps: 545, Total steps: 8273\n",
      "Episode: 9, Number of steps: 726, Total steps: 8999\n",
      "Episode: 10, Number of steps: 392, Total steps: 9391\n",
      "Episode: 11, Number of steps: 344, Total steps: 9735\n",
      "Episode: 12, Number of steps: 172, Total steps: 9907\n",
      "Episode: 13, Number of steps: 165, Total steps: 10072\n",
      "Episode: 14, Number of steps: 114, Total steps: 10186\n",
      "Episode: 15, Number of steps: 145, Total steps: 10331\n",
      "Episode: 16, Number of steps: 146, Total steps: 10477\n",
      "Episode: 17, Number of steps: 133, Total steps: 10610\n",
      "Episode: 18, Number of steps: 177, Total steps: 10787\n",
      "Episode: 19, Number of steps: 154, Total steps: 10941\n",
      "Episode: 20, Number of steps: 181, Total steps: 11122\n",
      "Episode: 21, Number of steps: 145, Total steps: 11267\n",
      "Episode: 22, Number of steps: 90, Total steps: 11357\n",
      "Episode: 23, Number of steps: 88, Total steps: 11445\n",
      "Episode: 24, Number of steps: 94, Total steps: 11539\n",
      "Episode: 25, Number of steps: 147, Total steps: 11686\n",
      "Episode: 26, Number of steps: 148, Total steps: 11834\n",
      "Episode: 27, Number of steps: 141, Total steps: 11975\n",
      "Episode: 28, Number of steps: 146, Total steps: 12121\n",
      "Episode: 29, Number of steps: 169, Total steps: 12290\n",
      "Episode: 30, Number of steps: 102, Total steps: 12392\n",
      "Episode: 31, Number of steps: 85, Total steps: 12477\n",
      "Episode: 32, Number of steps: 143, Total steps: 12620\n",
      "Episode: 33, Number of steps: 142, Total steps: 12762\n",
      "Episode: 34, Number of steps: 144, Total steps: 12906\n",
      "Episode: 35, Number of steps: 143, Total steps: 13049\n",
      "Episode: 36, Number of steps: 138, Total steps: 13187\n",
      "Episode: 37, Number of steps: 144, Total steps: 13331\n",
      "Episode: 38, Number of steps: 141, Total steps: 13472\n",
      "Episode: 39, Number of steps: 163, Total steps: 13635\n",
      "Episode: 40, Number of steps: 143, Total steps: 13778\n",
      "Episode: 41, Number of steps: 94, Total steps: 13872\n",
      "Episode: 42, Number of steps: 128, Total steps: 14000\n",
      "Episode: 43, Number of steps: 141, Total steps: 14141\n",
      "Episode: 44, Number of steps: 90, Total steps: 14231\n",
      "Episode: 45, Number of steps: 92, Total steps: 14323\n",
      "Episode: 46, Number of steps: 142, Total steps: 14465\n",
      "Episode: 47, Number of steps: 140, Total steps: 14605\n",
      "Episode: 48, Number of steps: 168, Total steps: 14773\n",
      "Episode: 49, Number of steps: 140, Total steps: 14913\n",
      "Average steps per episode: 298.26\n"
     ]
    }
   ],
   "source": [
    "for ep in range(max_episodes):\n",
    "    steps = 0\n",
    "    while True:\n",
    "        try:\n",
    "            # current state\n",
    "            current_state = observation # [x, x_dot]\n",
    "            action = agent.choose_action_eps_greedy(current_state)\n",
    "            # next state\n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "            # next action\n",
    "            next_action = agent.choose_action_eps_greedy(observation)\n",
    "            # env.render()\n",
    "\n",
    "            # update agent\n",
    "            if update_agent:\n",
    "                target = reward + agent.get_value(observation, next_action)\n",
    "                active_tiles = agent.get_active_tiles(current_state, action)\n",
    "                agent.update(active_tiles, target)\n",
    "\n",
    "            # save data\n",
    "            data_dict = {\n",
    "                col_name : col_data for col_name, col_data in zip(data_column_names, [ep, steps, current_state[0], current_state[1], action, reward, observation[0], observation[1], next_action])\n",
    "            }\n",
    "            data_collector.log_data(data_dict)\n",
    "\n",
    "            # prep the next iteration\n",
    "            steps += 1\n",
    "\n",
    "            # reset the training\n",
    "            if terminated or truncated:\n",
    "                observation, info = env.reset()\n",
    "                total_steps += steps\n",
    "                if debug:\n",
    "                    print(\"Episode: {}, Number of steps: {}, Total steps: {}\".format(ep, steps, total_steps))\n",
    "                break\n",
    "        except KeyboardInterrupt:\n",
    "            env.close()\n",
    "            data_collector.export_data(path, file_name)\n",
    "    # save data every few iterations\n",
    "    if save_every and (ep % save_every == 0):\n",
    "        data_collector.export_data(path, file_name)\n",
    "\n",
    "# training complete\n",
    "env.close()\n",
    "print(\"Average steps per episode: {}\".format(total_steps / max_episodes))\n",
    "data_collector.export_data(path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66eb0ff22152a42a55105d2627a5529bd8ce21fe81b81dbad1c4e8c0b6b69aac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
